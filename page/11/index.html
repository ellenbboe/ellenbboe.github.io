<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Microsoft YaHei:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png?v=5.1.4">


  <link rel="mask-icon" href="/images/safari-pinned-tab.svg?v=5.1.4" color="#222">


  <link rel="manifest" href="/images/site.manifest">


  <meta name="msapplication-config" content="/images/browserconfig.xml" />



  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="热爱生活的程序员">
<meta name="keywords" content="blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Eden">
<meta property="og:url" content="https://www.unblog.top/page/11/index.html">
<meta property="og:site_name" content="Eden">
<meta property="og:description" content="热爱生活的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Eden">
<meta name="twitter:description" content="热爱生活的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.unblog.top/page/11/"/>





  <title>Eden</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?070140e78adcb25cf2b649c2985789db";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Eden</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">中二少年的博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/18/2018-08-18/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/18/2018-08-18/" itemprop="url">2018-08-18</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-18T10:19:30+08:00">
                2018-08-18
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-18T10:22:00+08:00">
                2018-08-18
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/杂食动物/" itemprop="url" rel="index">
                    <span itemprop="name">杂食动物</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  334
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="SQL注入"><a href="#SQL注入" class="headerlink" title="SQL注入"></a>SQL注入</h3><p>所谓SQL注入，就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。<br><code>select * from username = ____ and password=_____</code><br><code>select * from username   &quot;test&quot; or &quot;&quot;=&quot;&quot; and password=&quot;123456&quot;</code></p>
<h3 id="XSS"><a href="#XSS" class="headerlink" title="XSS"></a>XSS</h3><p>XSS则是攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。<br><code>&lt;p style=&#39;color:red&#39;&gt;你好啊，尊敬的______&lt;p&gt;</code><br><code>&lt;p style=&#39;color:red&#39;&gt;你好啊，尊敬的 xxx&lt;script&gt;alert(1)&lt;/script&gt;&lt;p&gt;</code></p>
<h3 id="远程命令执行"><a href="#远程命令执行" class="headerlink" title="远程命令执行"></a>远程命令执行</h3><p>而远程命令执行，是用户通过浏览器提交执行命令，由于服务器端没有针对执行函数做过滤，导致执行命令。<br>ping  <strong>___</strong><br>ping <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> &amp; wget xxxxxxxxxxx</p>
<h3 id="越权"><a href="#越权" class="headerlink" title="越权"></a>越权</h3><p>越权漏洞是比较常见的漏洞类型，越权漏洞可以理解为，一个正常的用户A通常只能够对自己的一些信息进行增删改查，但是由于程序员的一时疏忽 ，对信息进行增删改查的时候没有进行一个判断，判断所需要操作的信息是否属于对应的用户，可以导致用户A可以操作其他人的信息。<br><code>Cookie: uid=11426;</code><br><code>Cookie: uid=1;</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/17/scrapy4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/17/scrapy4/" itemprop="url">Scrapy Pass 4</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-17T14:29:08+08:00">
                2018-08-17
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-17T14:30:54+08:00">
                2018-08-17
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,033
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  12
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Command-line-tool"><a href="#Command-line-tool" class="headerlink" title="Command line tool"></a>Command line tool</h2><p>New in version 0.10.</p>
<p>Scrapy is controlled through the <code>scrapy</code> command-line tool, to be referred here as the “Scrapy tool” to differentiate it from the sub-commands, which we just call “<code>commands</code>” or “<code>Scrapy commands</code>”.</p>
<p>The Scrapy tool provides several commands, for multiple purposes, and each one accepts a different set of arguments and options.</p>
<h3 id="Configuration-settings"><a href="#Configuration-settings" class="headerlink" title="Configuration settings"></a>Configuration settings</h3><p>Scrapy will <strong>look for</strong> configuration parameters in ini-style <code>scrapy.cfg</code> files in standard locations:</p>
<ol>
<li><code>/etc/scrapy.cfg</code> or <code>c:\scrapy\scrapy.cfg</code> (system-wide),</li>
<li>~/.config/scrapy.cfg ($XDG_CONFIG_HOME) and ~/.scrapy.cfg ($HOME) for global (user-wide) settings, and</li>
<li>scrapy.cfg inside a scrapy project’s root (see next section).<br>Settings from these files are merged in the listed order of preference: user-defined values have higher priority than system-wide defaults and project-wide settings will override all others, when defined.<br><strong>(优先级依次递增)</strong><br>Scrapy also understands, and can be configured through, a number of environment variables. Currently these are:</li>
</ol>
<blockquote>
<p>SCRAPY_SETTINGS_MODULE (see Designating the settings)<br>SCRAPY_PROJECT<br>SCRAPY_PYTHON_SHELL (see Scrapy shell)</p>
</blockquote>
<h3 id="Default-structure-of-Scrapy-projects"><a href="#Default-structure-of-Scrapy-projects" class="headerlink" title="Default structure of Scrapy projects"></a>Default structure of Scrapy projects</h3><p>Before delving into the command-line tool and its sub-commands, let’s first understand the directory structure of a Scrapy project.</p>
<p>Though it can be modified, all Scrapy projects have the same file structure by default, similar to this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg</span><br><span class="line">myproject/</span><br><span class="line">    __init__.py</span><br><span class="line">    items.py</span><br><span class="line">    middlewares.py</span><br><span class="line">    pipelines.py</span><br><span class="line">    settings.py</span><br><span class="line">    spiders/</span><br><span class="line">        __init__.py</span><br><span class="line">        spider1.py</span><br><span class="line">        spider2.py</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure></p>
<p>The directory where the <code>scrapy.cfg</code> file resides is known as the project root directory. <strong>That file</strong> contains the name of the python module that defines the project settings. Here is an example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[settings]</span><br><span class="line">default = myproject.settings</span><br></pre></td></tr></table></figure></p>
<h3 id="Using-the-scrapy-tool"><a href="#Using-the-scrapy-tool" class="headerlink" title="Using the scrapy tool"></a>Using the scrapy tool</h3><p>You can start by running the Scrapy tool with no arguments and it will print some usage help and the available commands:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Scrapy X.Y - no active project</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  scrapy &lt;command&gt; [options] [args]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  crawl         Run a spider</span><br><span class="line">  fetch         Fetch a URL using the Scrapy downloader</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure></p>
<p>The first line will print the currently active project if you’re inside a Scrapy project. In this example it was run from outside a project. If run from inside a project it would have printed something like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Scrapy X.Y - project: myproject</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  scrapy &lt;command&gt; [options] [args]</span><br><span class="line"></span><br><span class="line">[...]</span><br></pre></td></tr></table></figure></p>
<h3 id="Creating-projects"><a href="#Creating-projects" class="headerlink" title="Creating projects"></a>Creating projects</h3><p>The first thing you typically do with the scrapy tool is create your Scrapy project:<br><code>scrapy startproject myproject [project_dir]</code><br>That will create a Scrapy project under the project_dir directory. If project_dir wasn’t specified, project_dir will be the same as myproject.<br>Next, you go inside the new project directory:<br><code>cd project_dir</code><br>And you’re ready to use the <code>scrapy command</code> to manage and control your project from <strong>there</strong>(<strong>project_dir</strong>).</p>
<h3 id="Controlling-projects"><a href="#Controlling-projects" class="headerlink" title="Controlling projects"></a>Controlling projects</h3><p>You use the scrapy tool from inside your projects to control and manage them.<br>For example, to create a new spider:<br><code>scrapy genspider mydomain mydomain.com</code><br>Some Scrapy commands (like <code>crawl</code>) must be run from <strong>inside</strong> a Scrapy project.</p>
<p>Also keep in mind that some commands may have slightly different behaviours when running them from inside projects. For example, the fetch command will use spider-overridden behaviours (such as the <code>user_agent</code> attribute to override the user-agent) if the url being fetched is associated with some specific spider. This is intentional, as the fetch command is meant to be used to check how spiders are downloading pages.(注意某一些特殊命令会有不同的行为,这不废话吗)</p>
<h3 id="Available-tool-commands"><a href="#Available-tool-commands" class="headerlink" title="Available tool commands"></a>Available tool commands</h3><p>This section contains a list of the available built-in commands with a description and some usage examples. Remember, you can always get more info about each command by running:<br><code>scrapy &lt;command&gt; -h</code><br>And you can see all available commands with:<br><code>scrapy -h</code><br>There are <strong>two</strong> kinds of commands, those that only work from inside a Scrapy project (<strong>Project-specific commands</strong>) and those that also work without an active Scrapy project (<strong>Global commands</strong>), though they may behave slightly different when running from inside a project (as they would use the project overridden settings).</p>
<h4 id="Global-commands"><a href="#Global-commands" class="headerlink" title="Global commands:"></a>Global commands:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">startproject</span><br><span class="line">genspider</span><br><span class="line">settings</span><br><span class="line">runspider</span><br><span class="line">shell</span><br><span class="line">fetch</span><br><span class="line">view</span><br><span class="line">version</span><br></pre></td></tr></table></figure>
<h4 id="Project-only-commands"><a href="#Project-only-commands" class="headerlink" title="Project-only commands:"></a>Project-only commands:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">crawl</span><br><span class="line">check</span><br><span class="line">list</span><br><span class="line">edit</span><br><span class="line">parse</span><br><span class="line">bench</span><br></pre></td></tr></table></figure>
<h4 id="startproject-创建项目"><a href="#startproject-创建项目" class="headerlink" title="startproject(创建项目)"></a>startproject(创建项目)</h4><blockquote>
<p>Syntax: scrapy startproject &lt;project_name&gt; [project_dir]<br>Requires project: no</p>
</blockquote>
<p>Creates a new <code>Scrapy projec</code>t named <code>project_name</code>, under the project_dir directory. If <code>project_dir</code> wasn’t specified, <code>project_dir</code> will be the same as <code>project_name</code>.</p>
<p>Usage example:<br><code>$ scrapy startproject myproject</code></p>
<h4 id="genspider"><a href="#genspider" class="headerlink" title="genspider"></a>genspider</h4><blockquote>
<p>Syntax: scrapy genspider [-t template] <name> <domain><br>Requires project: no</domain></name></p>
</blockquote>
<p>Create a new spider in the current folder or in the current project’s spiders folder, if called from inside a project. The <strong><name></name></strong> parameter is set as the <strong>spider’s name</strong>, while <strong><domain></domain></strong> is used to <strong>generate the allowed_domains</strong> and <strong>start_urls</strong> spider’s attributes.</p>
<p>Usage example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider -l</span><br><span class="line">Available templates:</span><br><span class="line">  basic</span><br><span class="line">  crawl</span><br><span class="line">  csvfeed</span><br><span class="line">  xmlfeed</span><br><span class="line"></span><br><span class="line">$ scrapy genspider example example.com</span><br><span class="line">Created spider &apos;example&apos; using template &apos;basic&apos;</span><br><span class="line"></span><br><span class="line">$ scrapy genspider -t crawl scrapyorg scrapy.org</span><br><span class="line">Created spider &apos;scrapyorg&apos; using template &apos;crawl&apos;</span><br></pre></td></tr></table></figure></p>
<p>This is just a convenience shortcut command for creating spiders based on pre-defined templates, but certainly not the only way to create spiders. You can just create the spider source code files yourself, instead of using this command.</p>
<h4 id="crawl"><a href="#crawl" class="headerlink" title="crawl"></a>crawl</h4><blockquote>
<p>Syntax: scrapy crawl <spider><br>Requires project: yes<br>Start crawling using a spider.</spider></p>
</blockquote>
<p>Usage examples:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl myspider</span><br><span class="line">[ ... myspider starts crawling ... ]</span><br></pre></td></tr></table></figure></p>
<h4 id="check"><a href="#check" class="headerlink" title="check"></a>check</h4><blockquote>
<p>Syntax: scrapy check [-l] <spider><br>Requires project: yes<br>Run contract checks.(链接测试)</spider></p>
</blockquote>
<p>Usage examples:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy check -l</span><br><span class="line">first_spider</span><br><span class="line">  * parse</span><br><span class="line">  * parse_item</span><br><span class="line">second_spider</span><br><span class="line">  * parse</span><br><span class="line">  * parse_item</span><br><span class="line"></span><br><span class="line">$ scrapy check</span><br><span class="line">[FAILED] first_spider:parse_item</span><br><span class="line">&gt;&gt;&gt; &apos;RetailPricex&apos; field is missing</span><br><span class="line"></span><br><span class="line">[FAILED] first_spider:parse</span><br><span class="line">&gt;&gt;&gt; Returned 92 requests, expected 0..4</span><br></pre></td></tr></table></figure></p>
<h4 id="list-列出项目中的所有spider"><a href="#list-列出项目中的所有spider" class="headerlink" title="list(列出项目中的所有spider)"></a>list(列出项目中的所有spider)</h4><blockquote>
<p>Syntax: scrapy list<br>Requires project: yes<br>List all available <strong>spiders</strong> in the current project. The output is one spider per line.</p>
</blockquote>
<p>Usage example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy list</span><br><span class="line">spider1</span><br><span class="line">spider2</span><br></pre></td></tr></table></figure></p>
<h4 id="edit-编辑"><a href="#edit-编辑" class="headerlink" title="edit(编辑)"></a>edit(编辑)</h4><blockquote>
<p>Syntax: scrapy edit <spider><br>Requires project: yes<br>Edit the given spider using the editor defined in the EDITOR environment variable or (if unset) the EDITOR setting.<br>(我觉得我可能不会用到)</spider></p>
</blockquote>
<p>This command is provided only as a convenience shortcut for the most common case, the developer is of course free to choose any tool or IDE to write and debug spiders.</p>
<p>Usage example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy edit spider1</span><br></pre></td></tr></table></figure></p>
<h4 id="fetch-下载页面代码"><a href="#fetch-下载页面代码" class="headerlink" title="fetch (下载页面代码)"></a>fetch (下载页面代码)</h4><blockquote>
<p>Syntax: scrapy fetch <url><br>Requires project: no<br>Downloads the given URL using the Scrapy downloader and writes the contents to standard output.</url></p>
</blockquote>
<p>The interesting thing about this command is that it fetches the page how the spider would download it. For example, if the spider has a USER_AGENT attribute which overrides the User Agent, it will use that one.</p>
<p>So this command can be used to “see” how your spider would fetch a certain page.</p>
<p>If used <strong>outside a project</strong>, no particular per-spider behaviour would be applied and it will just use the <strong>default Scrapy downloader settings</strong>.</p>
<p>Supported options:</p>
<p><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider<br><code>--headers</code>: print the response’s HTTP headers instead of the response’s body<br><code>--no-redirect</code>: do not follow HTTP 3xx redirects (default is to follow them)</p>
<p>Usage examples:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy fetch --nolog http://www.example.com/some/page.html</span><br><span class="line">[ ... html content here ... ]</span><br><span class="line"></span><br><span class="line">$ scrapy fetch --nolog --headers http://www.example.com/</span><br><span class="line">&#123;&apos;Accept-Ranges&apos;: [&apos;bytes&apos;],</span><br><span class="line"> &apos;Age&apos;: [&apos;1263   &apos;],</span><br><span class="line"> &apos;Connection&apos;: [&apos;close     &apos;],</span><br><span class="line"> &apos;Content-Length&apos;: [&apos;596&apos;],</span><br><span class="line"> &apos;Content-Type&apos;: [&apos;text/html; charset=UTF-8&apos;],</span><br><span class="line"> &apos;Date&apos;: [&apos;Wed, 18 Aug 2010 23:59:46 GMT&apos;],</span><br><span class="line"> &apos;Etag&apos;: [&apos;&quot;573c1-254-48c9c87349680&quot;&apos;],</span><br><span class="line"> &apos;Last-Modified&apos;: [&apos;Fri, 30 Jul 2010 15:30:18 GMT&apos;],</span><br><span class="line"> &apos;Server&apos;: [&apos;Apache/2.2.3 (CentOS)&apos;]&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="view"><a href="#view" class="headerlink" title="view"></a>view</h4><blockquote>
<p>Syntax: scrapy view <url><br>Requires project: no<br>Opens the given URL in a browser, as your Scrapy spider would “see” it. Sometimes spiders see pages differently from regular users, so this can be used to check what the spider “sees” and confirm it’s what you expect.</url></p>
</blockquote>
<p>Supported options:</p>
<p><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider<br><code>--no-redirect</code>: do not follow HTTP 3xx redirects (default is to follow them)<br>Usage example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy view http://www.example.com/some/page.html</span><br><span class="line">[ ... browser starts ... ]</span><br></pre></td></tr></table></figure></p>
<h4 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h4><blockquote>
<p>Syntax: scrapy shell [url]<br>Requires project: no<br>Starts the Scrapy shell for the given URL (if given) or empty if no URL is given. Also supports UNIX-style local file paths, either relative with ./ or ../ prefixes or absolute file paths. See Scrapy shell for more info.</p>
</blockquote>
<p>Supported options:</p>
<p><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider<br><code>-c code</code>(设置返回状态): evaluate the code in the shell, print the result and exit<br><code>--no-redirect</code>: do not follow HTTP 3xx redirects (default is to follow them); this only affects the URL you may pass as argument on the command line; once you are inside the shell, fetch(url) will still follow HTTP redirects by default.<br>Usage example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy shell http://www.example.com/some/page.html</span><br><span class="line">[ ... scrapy shell starts ... ]</span><br><span class="line"></span><br><span class="line">$ scrapy shell --nolog http://www.example.com/ -c &apos;(response.status, response.url)&apos;</span><br><span class="line">(200, &apos;http://www.example.com/&apos;)</span><br><span class="line"></span><br><span class="line"># shell follows HTTP redirects by default</span><br><span class="line">$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c &apos;(response.status, response.url)&apos;</span><br><span class="line">(200, &apos;http://example.com/&apos;)</span><br><span class="line"></span><br><span class="line"># you can disable this with --no-redirect</span><br><span class="line"># (only for the URL passed as command line argument)</span><br><span class="line">$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c &apos;(response.status, response.url)&apos;</span><br><span class="line">(302, &apos;http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F&apos;)</span><br></pre></td></tr></table></figure></p>
<h4 id="parse"><a href="#parse" class="headerlink" title="parse"></a>parse</h4><blockquote>
<p>Syntax: scrapy parse <url> [options]<br>Requires project: yes<br>Fetches the given URL and parses it with the spider that handles it, using the method passed with the –callback option, or parse if not given.</url></p>
</blockquote>
<p>Supported options:</p>
<p><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider<br><code>--a NAME=VALUE</code>: set spider argument (may be repeated)<br><code>--callback or -c</code>: spider method to use as callback for parsing the response<br><code>--meta or -m</code>: additional request meta that will be passed to the callback request. This must be a valid json string. Example: –meta=’{“foo” : “bar”}’<br><code>--pipelines</code>: process items through pipelines<br><code>--rules or -r</code>: use CrawlSpider rules to discover the callback (i.e. spider method) to use for parsing the response<br><code>--noitems</code>: don’t show scraped items<br><code>--nolinks</code>: don’t show extracted links<br><code>--nocolour</code>: avoid using pygments to colorize the output<br><code>--depth or -d</code>: depth level for which the requests should be followed recursively (default: 1)<br><code>--verbose or -v</code>: display information for each depth level<br>Usage example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy parse http://www.example.com/ -c parse_item</span><br><span class="line">[ ... scrapy log lines crawling example.com spider ... ]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;</span><br><span class="line"># Scraped Items  ------------------------------------------------------------</span><br><span class="line">[&#123;&apos;name&apos;: u&apos;Example item&apos;,</span><br><span class="line"> &apos;category&apos;: u&apos;Furniture&apos;,</span><br><span class="line"> &apos;length&apos;: u&apos;12 cm&apos;&#125;]</span><br><span class="line"></span><br><span class="line"># Requests  -----------------------------------------------------------------</span><br><span class="line">[]</span><br></pre></td></tr></table></figure></p>
<h4 id="settings"><a href="#settings" class="headerlink" title="settings"></a>settings</h4><blockquote>
<p>Syntax: scrapy settings [options]<br>Requires project: no<br>Get the value of a Scrapy setting.</p>
</blockquote>
<p>If used inside a project it’ll show the project setting value, otherwise it’ll show the default Scrapy value for that setting.</p>
<p>Example usage:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy settings --get BOT_NAME</span><br><span class="line">scrapybot</span><br><span class="line">$ scrapy settings --get DOWNLOAD_DELAY</span><br><span class="line">0</span><br></pre></td></tr></table></figure></p>
<h4 id="runspider-单纯的运行文件"><a href="#runspider-单纯的运行文件" class="headerlink" title="runspider(单纯的运行文件)"></a>runspider(单纯的运行文件)</h4><blockquote>
<p>Syntax: scrapy runspider &lt;spider_file.py&gt;<br>Requires project: no<br>Run a spider self-contained in a Python file, without having to create a project.</p>
</blockquote>
<p>Example usage:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy runspider myspider.py</span><br><span class="line">[ ... spider starts crawling ... ]</span><br></pre></td></tr></table></figure></p>
<h4 id="version"><a href="#version" class="headerlink" title="version"></a>version</h4><blockquote>
<p>Syntax: scrapy version [-v]<br>Requires project: no<br>Prints the Scrapy version. If used with -v it also prints Python, Twisted and Platform info, which is useful for bug reports.</p>
</blockquote>
<h4 id="bench-估计用不着"><a href="#bench-估计用不着" class="headerlink" title="bench(估计用不着)"></a>bench(估计用不着)</h4><p>New in version 0.17.</p>
<blockquote>
<p>Syntax: scrapy bench<br>Requires project: no<br>Run a quick benchmark test. Benchmarking.</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/17/2018-08-17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/17/2018-08-17/" itemprop="url">2018-08-17</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-17T08:37:59+08:00">
                2018-08-17
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-17T08:39:42+08:00">
                2018-08-17
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/杂食动物/" itemprop="url" rel="index">
                    <span itemprop="name">杂食动物</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,672
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="暴露真实IP会遭到DDos攻击"><a href="#暴露真实IP会遭到DDos攻击" class="headerlink" title="暴露真实IP会遭到DDos攻击"></a>暴露真实IP会遭到DDos攻击</h3><p>(DDoS:Distributed Denial of Service)分布式拒绝攻击</p>
<p>Windows 用户“一般被默认授予管理员权限，那意味着他们几乎可以访问系统中的一切”。Linux，反而很好地限制了“root”权限</p>
<p>macos “通过隐匿实现的安全”，这秉承了“让软件内部运作保持专有，从而不为人知是抵御攻击的最好方法”的理念</p>
<p>Windows 的流行本身就是个问题，操作系统的安全性可能很大程度上依赖于装机用户量的规模。对于恶意软件作者来说，Windows 提供了大的施展平台。专注其中可以让他们的努力发挥最大作用。</p>
<h3 id="手机IMEI码"><a href="#手机IMEI码" class="headerlink" title="手机IMEI码"></a>手机IMEI码</h3><p>在手机拨号处输入”*#06#”得到手机IMEI码,相当于手机的身份证号码,移动运营商通过IMEI码分辨用户设备，追踪用户地理位置，记录用户拨打电话、发送短信、上网等行为。(可怕)</p>
<h3 id="python控制浏览器"><a href="#python控制浏览器" class="headerlink" title="python控制浏览器"></a>python控制浏览器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import webbrowser</span><br><span class="line">webbrowser.open(&apos;http://baidu.com&apos;)</span><br></pre></td></tr></table></figure>
<h3 id="pychram-安装第三方库失败解决方法"><a href="#pychram-安装第三方库失败解决方法" class="headerlink" title="pychram 安装第三方库失败解决方法"></a>pychram 安装第三方库失败解决方法</h3><p><code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package</code></p>
<h3 id="ed2k"><a href="#ed2k" class="headerlink" title="ed2k"></a>ed2k</h3><p><code>ed2k</code>全称叫“<code>eDonkey2000 network</code>”(电驴???)，是一种文件共享网络，最初用于共享音乐、电影和软件。与多数文件共享网络一样，它是分布式的；<strong>文件基于P2P原理存放于用户的电脑上而不是存储于一个中枢服务器</strong>。</p>
<p><code>eDonkey</code>客户端程序连接到这个网络来共享文件。而<code>eDonkey</code>服务器作为一个通讯中心，使用户在<code>ed2k</code>网络内查找文件。它的客户端和服务端可以工作于<code>Windows</code>、<code>Macintosh</code>(这是mac..汗颜)、<code>Linux</code>、<code>UNIX</code>操作系统。<strong>任何人</strong> 都可以作为服务器加入这个网络。由于服务器经常变化，客户端会经常更新它的服务器列表。<br><code>eDonkey</code>用混合MD4摘要算法检查来识别文件。<strong>这使ed2k网络可以将不同文件名的同一文件成功识别为一个文件，并使同一文件名的不同文件得以区分</strong>(厉害)。<code>eDonkeyd</code>的另一特性是：<strong>对大于9.8MB的文件，它在下载完成前将其分割；这将加速大型文件的发送</strong>。为了便于文件搜索，一些Web站点对比较热门的文件建立 ed2k链接 ，这些网站通常也提供热门服务器列表便于用户更新。</p>
<h3 id="fork-boom"><a href="#fork-boom" class="headerlink" title="fork boom"></a>fork boom</h3><p>fork炸弹（fork bomb）在计算机领域中是一种利用系统调用fork（或其他等效的方式）进行的<strong>拒绝服务攻击</strong>。与病毒与蠕虫不同的是，fork炸弹<strong>没有传染性</strong>，而且fork炸弹会使对<strong>同时执行进程、程序数设限的系统无法执行新程序</strong>，<strong>对于不设限的系统则使之停止响应</strong>。<br>fork炸弹通过进程递归式派生(fork，亦即自我复制)，以使<strong>系统拒绝服务甚至崩溃</strong>。</p>
<p>fork炸弹以极快的速度创建大量进程（进程数呈以2为底数的指数增长趋势），并以此<strong>消耗系统分配予进程的可用空间使进程表饱和</strong>，而系统在进程表饱和后就无法运行新程序，<strong>除非进程表中的某一进程终止</strong>；但由于fork炸弹程序所创建的所有实例都会不断探测空缺的进程槽并尝试取用以创建新进程，因而即使在某进程终止后也基本不可能运行新进程。fork炸弹生成的子程序在消耗进程表空间的同时也会占用CPU和内存，从而导致系统与现有进程运行速度放缓，响应时间也会随之大幅增加，以致于无法正常完成任务，从而使系统的正常运作受到严重影响。由于现代Unix操作系统普遍采用运用写实拷贝技术，fork炸弹通常不会使进程表饱和。<br>除了恶意触发fork炸弹破坏的情况外，软件开发中有时也会不慎在程序中嵌入fork炸弹，如在用于监听网络套接字并行使客户端-服务器结构系统中服务器端职责的应用程序中可能需要无限地进行循环（loop）与派生（fork）操作（类似下节示例程序所示），而在这种情况下源代码内的细微错误就可能在测试中“引爆”fork炸弹。<br>以下程序段就是由Jaromil所作的在类UNIX系统的shell环境下触发fork炸弹的shell脚本代码，总共只用了13个字符（包括空格）：<br><code>:(){ :|:&amp; };:</code><br>注解如下：</p>
<blockquote>
<p>:() # 定义函数,函数名为”:”,即每当输入”:”时就会自动调用{}内代码<br>{ # “:”函数开始标识<br>: # 用递归方式调用”:”函数本身<br>| # 并用管道(pipe)将其输出引至…<br>: # 另一次递归调用的”:”函数<br>综上,”:|:”表示的即是每次调用函数”:”的时候就会生成两份拷贝<br>&amp; # 调用间脱钩,以使最初的”:”函数被杀死后为其所调用的两个”:”函数还能继续执行<br>} # “:”函数结束标识<br>; # “:”函数定义结束后将要进行的操作…<br>: # 调用”:”函数,”引爆”fork炸弹<br>其中函数名“:”只是简化的一例，实际实现时可以随意设定，一个较易理解（将函数名替换为“forkbomb”）的版本如下：<br>forkbomb(){ forkbomb|forkbomb &amp;} ; forkbomb<br>(自身调用自身?….理解成死循环好了)</p>
</blockquote>
<p>Windows下则可以批处理命令如下实现：<br><code>%0|%0</code></p>
<p>POSIX标准下的C与C++的实现：<br><code>#include &lt;unistd.h&gt;int main(){while(1) fork();return0;}</code></p>
<p>Perl语言的实现：<br><code>fork while fork</code></p>
<p>在系统中成功“引爆”fork炸弹后，我们可重启来使系统恢复正常运行；而若要以手动的方法使fork炸弹“熄火”，那前提就是必须杀死fork炸弹产生的所有进程。为此我们可以考虑使用程序来杀死fork炸弹产生的进程，但由于这一般需要创建新进程，且由于fork炸弹一直在探测与占用进程槽与内存空间，因而这一方法几乎不可能实现，而且用kill命令杀死进程后，释放出的进程槽又会被余下的fork炸弹线程所产生的新进程占用，<br>在Windows下，用户可以退出当前用户会话的方式使系统恢复正常，但此法奏效的前提是fork炸弹是在该用户的特定会话内触发的</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/16/scrapy3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/16/scrapy3/" itemprop="url">Scrapy Pass 3</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-16T18:59:48+08:00">
                2018-08-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-16T19:01:23+08:00">
                2018-08-16
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,368
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Learn-Scrapy-pass-3"><a href="#Learn-Scrapy-pass-3" class="headerlink" title="Learn Scrapy pass 3"></a>Learn Scrapy pass 3</h2><h3 id="接上文Extract-data"><a href="#接上文Extract-data" class="headerlink" title="接上文Extract data"></a>接上文Extract data</h3><h4 id="Extracting-quotes-and-authors"><a href="#Extracting-quotes-and-authors" class="headerlink" title="Extracting quotes and authors"></a>Extracting quotes and authors</h4><p>Now that you know a bit about <code>selection</code> and <code>extraction</code>, let’s complete our spider by writing the code to extract the quotes from the web page.</p>
<p>Each quote in <code>http://quotes.toscrape.com</code>is represented by HTML elements that look like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;quote&quot;&gt;</span><br><span class="line">    &lt;span class=&quot;text&quot;&gt;“The world as we have created it is a process of our</span><br><span class="line">    thinking. It cannot be changed without changing our thinking.”&lt;/span&gt;</span><br><span class="line">    &lt;span&gt;</span><br><span class="line">        by &lt;small class=&quot;author&quot;&gt;Albert Einstein&lt;/small&gt;</span><br><span class="line">        &lt;a href=&quot;/author/Albert-Einstein&quot;&gt;(about)&lt;/a&gt;</span><br><span class="line">    &lt;/span&gt;</span><br><span class="line">    &lt;div class=&quot;tags&quot;&gt;</span><br><span class="line">        Tags:</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/change/page/1/&quot;&gt;change&lt;/a&gt;</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/deep-thoughts/page/1/&quot;&gt;deep-thoughts&lt;/a&gt;</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/thinking/page/1/&quot;&gt;thinking&lt;/a&gt;</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/world/page/1/&quot;&gt;world&lt;/a&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure></p>
<p>Let’s open up scrapy shell and play a bit to find out how to extract the data we want:<br><code>$ scrapy shell &#39;http://quotes.toscrape.com&#39;</code><br>We get a <strong>list</strong> of selectors for the quote HTML elements with:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;div.quote&quot;)</span><br></pre></td></tr></table></figure></p>
<p>Each of the selectors <strong>returned by the query</strong> above allows us to run further queries over their sub-elements. Let’s assign the first selector to a variable, so that we can run our CSS selectors directly on a particular quote:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; quote = response.css(&quot;div.quote&quot;)[0]</span><br></pre></td></tr></table></figure></p>
<p>Now, let’s extract title, author and the tags from that quote using the quote object we just created:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; title = quote.css(&quot;span.text::text&quot;).extract_first()</span><br><span class="line">&gt;&gt;&gt; title</span><br><span class="line">&apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;</span><br><span class="line">&gt;&gt;&gt; author = quote.css(&quot;small.author::text&quot;).extract_first()</span><br><span class="line">&gt;&gt;&gt; author</span><br><span class="line">&apos;Albert Einstein&apos;</span><br></pre></td></tr></table></figure></p>
<p>Given that the tags are a <strong>list</strong> of strings, we can use the <code>.extract()</code> method to get all of them:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; tags = quote.css(&quot;div.tags a.tag::text&quot;).extract()</span><br><span class="line">&gt;&gt;&gt; tags</span><br><span class="line">[&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;]</span><br></pre></td></tr></table></figure></p>
<p>Having figured out how to extract each bit, we can now iterate over all the quotes elements and put them together into a Python dictionary:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for quote in response.css(&quot;div.quote&quot;):</span><br><span class="line">...     text = quote.css(&quot;span.text::text&quot;).extract_first()</span><br><span class="line">...     author = quote.css(&quot;small.author::text&quot;).extract_first()</span><br><span class="line">...     tags = quote.css(&quot;div.tags a.tag::text&quot;).extract()</span><br><span class="line">...     print(dict(text=text, author=author, tags=tags))</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;], &apos;author&apos;: &apos;Albert Einstein&apos;, &apos;text&apos;: &apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;&#125;</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;abilities&apos;, &apos;choices&apos;], &apos;author&apos;: &apos;J.K. Rowling&apos;, &apos;text&apos;: &apos;“It is our choices, Harry, that show what we truly are, far more than our abilities.”&apos;&#125;</span><br><span class="line">    ... a few more of these, omitted for brevity</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Extracting-data-in-our-spider"><a href="#Extracting-data-in-our-spider" class="headerlink" title="Extracting data in our spider"></a>Extracting data in our spider</h4><p>Let’s get back to our spider. Until now, it doesn’t extract any data in particular, just saves the whole HTML page to a local file <em>(额)</em> . Let’s integrate the extraction logic(逻辑) above into our spider.</p>
<p>A Scrapy spider typically <strong>generates many dictionaries</strong> containing the data extracted from the page. To do that, we use the <strong>yield</strong> Python keyword in the callback, as you can see below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/2/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),</span><br><span class="line">            &#125;</span><br><span class="line">            (yield 不断调用,似乎不用储存)</span><br></pre></td></tr></table></figure></p>
<p>If you run this spider, it will output the extracted data with the log:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;life&apos;, &apos;love&apos;], &apos;author&apos;: &apos;André Gide&apos;, &apos;text&apos;: &apos;“It is better to be hated for what you are than to be loved for what you are not.”&apos;&#125;</span><br><span class="line">2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;edison&apos;, &apos;failure&apos;, &apos;inspirational&apos;, &apos;paraphrased&apos;], &apos;author&apos;: &apos;Thomas A. Edison&apos;, &apos;text&apos;: &quot;“I have not failed. I&apos;ve just found 10,000 ways that won&apos;t work.”&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Storing-the-scraped-data"><a href="#Storing-the-scraped-data" class="headerlink" title="Storing the scraped data"></a>Storing the scraped data</h4><p>The simplest way to store the scraped data is by using <strong>Feed exports</strong>, with the following command:<br><code>scrapy crawl quotes -o quotes.json</code></p>
<p>That will generate an quotes.json file containing all scraped items, serialized in <code>JSON</code>.</p>
<p>For historic reasons, Scrapy <strong>appends to</strong> a given file <strong>instead of overwriting</strong> its contents. If you run this command twice without removing the file before the second time, you’ll end up with a broken JSON file.<br><strong>(两次使用会损坏json文件)</strong><br>You can also use other formats, like JSON Lines:<br><code>scrapy crawl quotes -o quotes.jl</code></p>
<blockquote>
<p>The JSON Lines format is useful because it’s <strong>stream-like</strong>, <strong>you can easily append new records to it.</strong> It doesn’t have the same problem of JSON when you run twice. Also, <strong>as each record is a separate line</strong>, you can process big files without having to fit everything in memory, there are tools like JQ to help doing that at the command-line.</p>
</blockquote>
<p>In small projects (like the one in this tutorial), that should be enough. However, if you want to <strong>perform more complex things with the scraped items, you can write an Item Pipeline</strong>. A placeholder file for Item Pipelines has been set up for you when the project is created, in tutorial/pipelines.py.<strong>(预先创建好了pipelines文件)</strong> Though you <strong>don’t need to implement any item pipelines</strong> if you just want to store the scraped items.</p>
<h4 id="Following-links"><a href="#Following-links" class="headerlink" title="Following links"></a>Following links</h4><p>Let’s say, instead of just scraping the stuff from the first two pages from <code>http://quotes.toscrape.com</code>, you want quotes from all the pages in the website.</p>
<p>Now that you know how to extract data from pages, let’s see how to follow links from them.</p>
<p>First thing is to extract the link to the page we want to follow. Examining our page, we can see there is a link to the next page with the following markup:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;ul class=&quot;pager&quot;&gt;</span><br><span class="line">    &lt;li class=&quot;next&quot;&gt;</span><br><span class="line">        &lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;&amp;rarr;&lt;/span&gt;&lt;/a&gt;</span><br><span class="line">    &lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br></pre></td></tr></table></figure></p>
<p>We can try extracting it in the shell:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;li.next a&apos;).extract_first()</span><br><span class="line">&apos;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;→&lt;/span&gt;&lt;/a&gt;&apos;</span><br></pre></td></tr></table></figure></p>
<p>This gets the anchor element, but we want the attribute href. For that, Scrapy supports a CSS extension that let’s you select the attribute contents, like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">&apos;/page/2/&apos;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see now our spider modified to recursively follow the link to the next page, extracting data from it:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            yield scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p>Now, after extracting the data, the parse() method looks for the link to the next page, builds a full absolute URL <strong>using the urljoin() method</strong> (since the links can be relative) and yields a new request to the next page, registering itself <strong>as callback</strong> to <strong>handle the data</strong> extraction for the next page and to keep the crawling going through all the pages.</p>
<p>What you see here is Scrapy’s mechanism(机制) of following links: <strong>when you yield a Request in a callback method, Scrapy will schedule that request to be sent and register a callback method to be executed when that request finishes.</strong></p>
<p>Using this, you can build complex crawlers that follow links according to rules you define, and extract different kinds of data depending on the page it’s visiting.</p>
<p>In our example, it creates a sort of loop, following all the links to the next page until it doesn’t find one – handy for crawling blogs, forums and other sites with pagination.</p>
<h4 id="A-shortcut-for-creating-Requests"><a href="#A-shortcut-for-creating-Requests" class="headerlink" title="A shortcut for creating Requests"></a>A shortcut for creating Requests</h4><p>As a shortcut for creating Request objects you can use response.follow:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;span small::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            yield response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p>Unlike scrapy.Request, <strong>response.follow supports relative URLs directly - no need to call urljoin</strong>.(震惊,似乎挺厉害的) Note that response.follow just returns a Request instance; you still have to yield this Request.</p>
<p>You can also pass a selector to response.follow instead of a string; this selector should extract necessary attributes:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for href in response.css(&apos;li.next a::attr(href)&apos;):</span><br><span class="line">    yield response.follow(href, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p>For <a> elements there is a shortcut: response.follow uses their href attribute automatically. So the code can be shortened further:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for a in response.css(&apos;li.next a&apos;):</span><br><span class="line">    yield response.follow(a, callback=self.parse)</span><br></pre></td></tr></table></figure></a></p>
<p><strong>Note</strong><br><code>response.follow(response.css(&#39;li.next a&#39;))</code> is not valid because <code>response.css</code> returns a list-like object with selectors for all results, not a single selector. A for loop like in the example above, or <code>response.follow(response.css(&#39;li.next a&#39;)[0])</code> is fine.</p>
<h4 id="More-examples-and-patterns"><a href="#More-examples-and-patterns" class="headerlink" title="More examples and patterns"></a>More examples and patterns</h4><p>Here is another spider that illustrates callbacks and following links, this time for scraping author information:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class AuthorSpider(scrapy.Spider):</span><br><span class="line">    name = &apos;author&apos;</span><br><span class="line">    start_urls = [&apos;http://quotes.toscrape.com/&apos;]</span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # follow links to author pages</span><br><span class="line">        for href in response.css(&apos;.author + a::attr(href)&apos;):</span><br><span class="line">            yield response.follow(href, self.parse_author)</span><br><span class="line"></span><br><span class="line">        # follow pagination links</span><br><span class="line">        for href in response.css(&apos;li.next a::attr(href)&apos;):</span><br><span class="line">            yield response.follow(href, self.parse)</span><br><span class="line"></span><br><span class="line">    def parse_author(self, response):</span><br><span class="line">        def extract_with_css(query):</span><br><span class="line">            return response.css(query).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        yield &#123;</span><br><span class="line">            &apos;name&apos;: extract_with_css(&apos;h3.author-title::text&apos;),</span><br><span class="line">            &apos;birthdate&apos;: extract_with_css(&apos;.author-born-date::text&apos;),</span><br><span class="line">            &apos;bio&apos;: extract_with_css(&apos;.author-description::text&apos;),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p>
<p>This spider will start from the main page, it will follow all the links to the authors pages calling the parse_author callback for each of them, and also the pagination links with the parse callback as we saw before.</p>
<p>Here we’re passing callbacks to response.follow as positional arguments to make the code shorter; it also works for <code>scrapy.Request</code>.</p>
<p>The parse_author callback <strong>defines a helper function</strong> to extract and cleanup the data from a CSS query and yields the Python dict with the author data.</p>
<p>Another interesting thing this spider demonstrates(显示) is that, even if there are many quotes from the same author, we don’t need to worry about visiting the same author page multiple times. By default, Scrapy filters out duplicated requests to URLs already visited, avoiding the problem of hitting servers too much because of a programming mistake. This can be configured by the setting DUPEFILTER_CLASS.(不用担心死循环)</p>
<p>Hopefully by now you have a good understanding of how to use the mechanism of following links and callbacks with Scrapy.</p>
<p>As yet another example spider that leverages the mechanism of following links, check out the CrawlSpider class for a generic spider that implements a small rules engine that you can use to write your crawlers on top of it.(可以写自己的规则?是这个意思吧)<br>Also, a common pattern is to build an item with data from more than one page, using <a href="https://doc.scrapy.org/en/latest/topics/request-response.html#topics-request-response-ref-request-callback-arguments" target="_blank" rel="noopener">a trick to pass additional data to the callbacks</a>.</p>
<h4 id="Using-spider-arguments"><a href="#Using-spider-arguments" class="headerlink" title="Using spider arguments"></a>Using spider arguments</h4><p>You can provide command line arguments to your spiders by using the -a option when running them:<br><code>scrapy crawl quotes -o quotes-humor.json -a tag=humor</code><br>(使用-a选项 添加attr)<br>These arguments are passed to the Spider’s __init__ method and become spider attributes by default.</p>
<p>In this example, the value provided for the tag argument will be available via self.tag. You can use this to make your spider fetch only quotes with a specific tag, building the URL based on the argument:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    def start_requests(self):</span><br><span class="line">        url = &apos;http://quotes.toscrape.com/&apos;</span><br><span class="line">        tag = getattr(self, &apos;tag&apos;, None)</span><br><span class="line">        if tag is not None:</span><br><span class="line">            url = url + &apos;tag/&apos; + tag</span><br><span class="line">        yield scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">            &#125;(先处理得到的文本)</span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        (再去获取下一个page)</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            yield response.follow(next_page, self.parse)</span><br></pre></td></tr></table></figure></p>
<p>If you pass the <code>tag=humor</code> argument to this spider, you’ll notice that it will only visit URLs from the humor tag, such as <code>http://quotes.toscrape.com/tag/humor</code>.</p>
<p>You can learn more about <a href="https://doc.scrapy.org/en/latest/topics/spiders.html#spiderargs" target="_blank" rel="noopener">handling spider arguments here</a>.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/7.jpg"
                alt="兔子春" />
            
              <p class="site-author-name" itemprop="name">兔子春</p>
              <p class="site-description motion-element" itemprop="description">热爱生活的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">80</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/apersonlikesc" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:ztb52cgfls@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heartbeat"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">由一位中二艺术家创作</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">93.6k</span>
  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Evernote,Mailto";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

</body>
</html>
